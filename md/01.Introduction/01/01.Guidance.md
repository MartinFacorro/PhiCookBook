### Guidance-AI and Phi Models as a Service (MaaS)
We are bringing [Guidance](https://github.com/guidance-ai/guidance) to the Phi-3.5-mini serverless endpoint offering in Azure AI Foundry to make outputs more predictable through defining the structure tailored to an application. With Guidance, you can eliminate expensive retries, and can, for example, constrain the model to select from pre-defined lists (e.g., medical codes), restrict outputs to direct quotes from provided context, or follow in any regex. Guidance steers the model token by token in the inference stack, reducing cost and latency by 30-50%, which makes it a unique and valuable add-on to the [Phi-3-mini serverless endpoint](https://aka.ms/try-phi3.5mini).

## [**Guidance-AI**](https://github.com/guidance-ai/guidance) is a framework designed to help developers create and deploy AI models efficiently. It focuses on providing tools and best practices for building robust AI applications. 

When combined with **Phi Models as a Service (MaaS)**, it offers a powerful solution for deploying small language models (SLMs) that are both cost-effective and high-performing.

**Guidance-AI** is a programming framework designed to help developers control and steer large language models (LLMs) more effectively. It allows for precise structuring of outputs, reducing latency and cost compared to traditional prompting or fine-tuning methods.

### Key Features of Guidance-AI:
- **Efficient Control**: Enables developers to control how the language model generates text, ensuring high-quality and relevant outputs.
- **Cost and Latency Reduction**: Optimizes the generation process to be more cost-effective and faster.
- **Flexible Integration**: Works with various backends, including Transformers, llama.cpp, AzureAI, VertexAI, and OpenAI.
- **Rich Output Structures**: Supports complex output structures like conditionals, loops, and tool use, making it easier to generate clear and parsable results.
- **Compatibility**: Allows a single Guidance program to be executed on multiple backends, enhancing flexibility and ease of use.

### Example Use Cases:
- **Constrained Generation**: Using regular expressions and context-free grammars to guide the model's output.
- **Tool Integration**: Automatically interleaving control and generation, such as using a calculator within a text generation task.

For more detailed information and examples, you can check out the [Guidance-AI GitHub repository](https://github.com/guidance-ai/guidance).

[Check out the Phi-3.5 Sample](../../../code/01.Introduce/guidance.ipynb)

### Key Features of Phi Models:
1. **Cost-Effective**: Designed to be affordable while maintaining high performance.
2. **Low Latency**: Ideal for real-time applications requiring quick responses.
3. **Flexibility**: Can be deployed in various environments, including cloud, edge, and offline scenarios.
4. **Customization**: Models can be fine-tuned with domain-specific data to enhance performance.
5. **Security and Compliance**: Built with Microsoft's AI principles, ensuring accountability, transparency, fairness, reliability, safety, privacy, and inclusiveness.

### Phi Models as a Service (MaaS):
Phi models are available through a pay-as-you-go billing system via inference APIs, making it easy to integrate them into your applications without significant upfront costs.

### Getting Started with Phi-3:
To start using Phi models, you can explore the [Azure AI model catalog](https://ai.azure.com/explore/models) or the GitHub Marketplace Models](https://github.com/marketplace/models) which offers prebuilt and customizable models. Additionally, you can use tools like [Azure AI Foundry](https://ai.azure.com) to develop and deploy your AI applications.

### Resources
[Sample Notebook on getting started with Guidance](../../../code/01.Introduce/guidance.ipynb)
